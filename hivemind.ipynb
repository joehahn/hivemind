{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hivemind.ipynb\n",
    "#\n",
    "#by Joe Hahn\n",
    "#jmh.datasciences@gmail.com\n",
    "#3 March 2018\n",
    "#\n",
    "#This illustrates how to play the hivemind game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#generate small sample of bucket_yields\n",
    "N_fields = 4\n",
    "lag = 1\n",
    "N_turns = 20\n",
    "SNR = 1.1                       #signal/noise ratio\n",
    "rn_seed = 14\n",
    "from hivemind import *\n",
    "np.random.seed(seed=rn_seed)\n",
    "actual_field_yields, best_field, lagged_field_yields, weather, weather_onehot, field_yield_mean, \\\n",
    "    field_yield_sigma = make_bucket_yields(N_fields, N_turns, SNR, lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual_field_yields =  [ 0.          0.00155707 -0.00274039  0.00565763] best_field =  [ 0.  0.  0.  1.]\n",
      "actual_field_yields =  [ 0.          0.00330989  0.00276882  0.00506664] best_field =  [ 0.  0.  0.  1.]\n",
      "actual_field_yields =  [ 0.          0.00260652  0.00579083  0.00853607] best_field =  [ 0.  0.  0.  1.]\n",
      "actual_field_yields =  [ 0.         -0.00119987 -0.00021855  0.00880094] best_field =  [ 0.  0.  0.  1.]\n",
      "actual_field_yields =  [ 0.          0.00017922  0.00610507  0.0089685 ] best_field =  [ 0.  0.  0.  1.]\n",
      "actual_field_yields =  [ 0.          0.00135119  0.00735315  0.00083518] best_field =  [ 0.  0.  1.  0.]\n",
      "actual_field_yields =  [ 0.         -0.00106928 -0.00618294 -0.00956718] best_field =  [ 1.  0.  0.  0.]\n",
      "actual_field_yields =  [ 0.          0.00015585  0.00845787  0.00356163] best_field =  [ 0.  0.  1.  0.]\n",
      "actual_field_yields =  [ 0.         -0.00011855 -0.00323185 -0.00191733] best_field =  [ 1.  0.  0.  0.]\n",
      "actual_field_yields =  [ 0.          0.00088272  0.00350475 -0.00574907] best_field =  [ 0.  0.  1.  0.]\n",
      "actual_field_yields =  [ 0.         -0.00202811  0.00374581  0.00132914] best_field =  [ 0.  0.  1.  0.]\n",
      "actual_field_yields =  [ 0.          0.00433312 -0.00450637 -0.01109005] best_field =  [ 0.  1.  0.  0.]\n",
      "actual_field_yields =  [ 0.          0.00371889  0.00780978  0.00351718] best_field =  [ 0.  0.  1.  0.]\n",
      "actual_field_yields =  [ 0.          0.00178114 -0.00638748 -0.01332931] best_field =  [ 0.  1.  0.  0.]\n",
      "actual_field_yields =  [ 0.         -0.00285815 -0.00571154 -0.00976573] best_field =  [ 1.  0.  0.  0.]\n",
      "actual_field_yields =  [ 0.         -0.00496317 -0.00174297 -0.00045012] best_field =  [ 1.  0.  0.  0.]\n",
      "actual_field_yields =  [ 0.          0.00236138  0.00269843  0.00923638] best_field =  [ 0.  0.  0.  1.]\n",
      "actual_field_yields =  [ 0.          0.00089294  0.00197509 -0.00559052] best_field =  [ 0.  0.  1.  0.]\n",
      "actual_field_yields =  [ 0.          0.00268364  0.00386722 -0.00033771] best_field =  [ 0.  0.  1.  0.]\n",
      "actual_field_yields =  [ 0.          0.00153835  0.00356546 -0.00138705] best_field =  [ 0.  0.  1.  0.]\n"
     ]
    }
   ],
   "source": [
    "#print actual_field_yields & note that best_field=1 for field having highest actual_field_yields\n",
    "for idx in range(N_turns):\n",
    "    print 'actual_field_yields = ', actual_field_yields[idx], 'best_field = ', best_field[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print lagged_bucket_yields & note that lagged_bucket_yields is lagged by 1 record\n",
    "for idx in range(N_turns):\n",
    "    print 'lagged_bucket_yields = ', lagged_bucket_yields[idx], 'best_bucket = ', best_bucket[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note that actual_bucket_yields tend to be negative during hot or stormy weather \n",
    "for idx in range(N_turns):\n",
    "    print 'weather = ', weather[idx], '    weather_onehot = ', weather_onehot[idx], \\\n",
    "        'actl_byls = ', actual_bucket_yields[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate larger sample of bucket_yields\n",
    "N_buckets = 60\n",
    "lag = 1\n",
    "N_turns = 100\n",
    "rn_seed = 14\n",
    "from hivemind import *\n",
    "np.random.seed(seed=rn_seed)\n",
    "actual_bucket_yields, best_bucket, lagged_bucket_yields, weather, weather_onehot, bucket_yield_mean, \\\n",
    "    bucket_yield_sigma = make_bucket_yields(N_buckets, N_turns, SNR, lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prep matplotlib\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(font_scale=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot loss vs training epoch...note that bucket_yield_mean has signal/noise=2\n",
    "fig, ax = plt.subplots(1,1, figsize=(15, 6))\n",
    "xp = np.arange(N_buckets)\n",
    "yp = bucket_yield_mean\n",
    "ax.plot(xp, yp, linewidth=1, marker='o', markersize=5, label='bucket_yield_mean')\n",
    "yp = bucket_yield_sigma\n",
    "ax.plot(xp, yp, linewidth=1, marker='o', markersize=5, label='bucket_yield_sigma')\n",
    "ax.set_title('bucket yield parameters')\n",
    "ax.set_ylabel('bucket yield')\n",
    "ax.set_xlabel('bucket number')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#play single small game and compute net_values vs turn\n",
    "strategy = 'high'\n",
    "N_buckets = 6\n",
    "SNR = 1.1\n",
    "lag = 1\n",
    "N_turns = 100\n",
    "actual_bucket_yields, best_bucket, lagged_bucket_yields, weather, weather_onehot, bucket_yield_mean, \\\n",
    "    bucket_yield_sigma = make_bucket_yields(N_buckets, N_turns, SNR, lag)\n",
    "net_values = compute_net_value(actual_bucket_yields, lagged_bucket_yields, weather, weather_onehot, strategy)\n",
    "net_values.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#play 10 games per each strategy and plot their average compound_value vs turn\n",
    "N_games = 10\n",
    "N_buckets = 60\n",
    "lag = 1\n",
    "N_turns = 100\n",
    "strategies = ['low', 'middle', 'high', 'top']\n",
    "fig, ax = plt.subplots(1,1, figsize=(15, 6))\n",
    "all_net_values = pd.DataFrame()\n",
    "for strategy in strategies:\n",
    "    for idx in range(N_games):\n",
    "        actual_bucket_yields, _, lagged_bucket_yields, _, _, _, _ = make_bucket_yields(N_buckets, N_turns, SNR, lag)\n",
    "        net_values = compute_net_value(actual_bucket_yields, lagged_bucket_yields, weather, weather_onehot, \\\n",
    "            strategy, model=None)\n",
    "        net_values['strategy'] = strategy\n",
    "        all_net_values = all_net_values.append(net_values, ignore_index=True)\n",
    "g = all_net_values.groupby(['strategy', 'turn'], as_index=False)['compound_value'].agg(['mean', 'std', 'count'])\n",
    "for strategy in strategies:\n",
    "    strategy_results = g.loc[strategy]\n",
    "    xp = strategy_results.index\n",
    "    yp = strategy_results['mean'].values\n",
    "    yerr = strategy_results['std'].values\n",
    "    p = ax.plot(xp, yp, linewidth=1, marker='o', markersize=5, label=strategy)\n",
    "    p = ax.errorbar(xp, yp, yerr=yerr, alpha=0.4, color=p[0].get_color())\n",
    "p = ax.set_title('mean compound_value generated by various strategies')\n",
    "p = ax.set_ylabel('compound_value')\n",
    "p = ax.set_xlabel('turn')\n",
    "p = ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate lots of test-train-validate data: lagged_bucket_yields and best_bucket\n",
    "N_buckets = 60\n",
    "lag = 1\n",
    "SNR = 1.1\n",
    "N_turns = 100000\n",
    "actual_bucket_yields, best_bucket, lagged_bucket_yields, weather, weather_onehot, bucket_yield_mean, \\\n",
    "    bucket_yield_sigma = make_bucket_yields(N_buckets, N_turns, SNR, lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check class imbalance\n",
    "idx = (weather == 'nominal')\n",
    "yp = best_bucket.sum(axis=0)\n",
    "xp = np.arange(len(yp))\n",
    "fig, ax = plt.subplots(1,1, figsize=(15, 6))\n",
    "p = ax.plot(xp, yp, linewidth=3)\n",
    "p = ax.set_title('number of times each bucket is best')\n",
    "p = ax.set_ylabel(\"number of best_bucket's\")\n",
    "p = ax.set_xlabel('bucket number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features x = lagged_bucket_yields + weather_onehot\n",
    "x = np.concatenate((lagged_bucket_yields, weather_onehot), axis=1)\n",
    "idx = 4\n",
    "print 'lagged_bucket_yields = ', lagged_bucket_yields[idx]\n",
    "print 'weather_onehot = ', weather_onehot[idx]\n",
    "print 'x = ', x[idx]\n",
    "#target y = best_bucket\n",
    "y = best_bucket\n",
    "print 'y = ', y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test-train-validation split is 1:1:1\n",
    "train_fraction = 0.333\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test_validate, y_train, y_test_validate = train_test_split(x, y, train_size=train_fraction, \n",
    "    test_size=(1-train_fraction), random_state=rn_seed)\n",
    "train_fraction = 0.5\n",
    "x_test, x_validate, y_test, y_validate = \\\n",
    "    train_test_split(x_test_validate, y_test_validate, train_size=train_fraction, random_state=rn_seed)\n",
    "print x.shape, y.shape\n",
    "print x_train.shape, y_train.shape\n",
    "print x_test.shape, y_test.shape\n",
    "print x_validate.shape, y_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#build MLP classification model \n",
    "N_inputs = x.shape[1]\n",
    "N_outputs = y.shape[1]\n",
    "N_middle_layer = 0*N_outputs\n",
    "dropout_fraction = 0.0\n",
    "model = mlp_classifier(N_inputs, N_middle_layer, N_outputs, dropout_fraction)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#fit model to predict most productive bucket\n",
    "N_epochs = 25\n",
    "batch_size = N_turns/100\n",
    "print 'layers = ', N_inputs, N_middle_layer, N_outputs\n",
    "print 'dropout_fraction = ', dropout_fraction\n",
    "model = mlp_classifier(N_inputs, N_middle_layer, N_outputs, dropout_fraction)\n",
    "fit_history = model.fit(x_train, y_train, batch_size=batch_size, epochs=N_epochs, verbose=0, \n",
    "    validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot loss vs training epoch\n",
    "fig, ax = plt.subplots(1,1, figsize=(15, 6))\n",
    "xp = fit_history.epoch\n",
    "yp = fit_history.history['loss']\n",
    "p = ax.plot(xp, yp, linewidth=1, label='training sample')\n",
    "yp = fit_history.history['val_loss']\n",
    "p = ax.plot(xp, yp, linewidth=1, label='validation sample')\n",
    "p = ax.set_title('loss function versus training epoch')\n",
    "p = ax.set_ylabel('loss function')\n",
    "p = ax.set_xlabel('training epoch')\n",
    "p = ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#play 10 short games using each strategy and plot their mean compound_value\n",
    "N_games = 10\n",
    "N_turns = 100\n",
    "top_k = 6\n",
    "strategies = ['low', 'middle', 'high', 'top', 'smart']\n",
    "fig, ax = plt.subplots(1,1, figsize=(15, 6))\n",
    "all_net_values = pd.DataFrame()\n",
    "for strategy in strategies:\n",
    "    for idx in range(N_games):\n",
    "        actual_bucket_yields, best_bucket, lagged_bucket_yields, weather, weather_onehot, bucket_yield_mean, \\\n",
    "            bucket_yield_sigma = make_bucket_yields(N_buckets, N_turns, SNR, lag)\n",
    "        net_values = compute_net_value(actual_bucket_yields, lagged_bucket_yields, weather, weather_onehot, \\\n",
    "            strategy, model=model, top_k=top_k)\n",
    "        net_values['strategy'] = strategy\n",
    "        all_net_values = all_net_values.append(net_values, ignore_index=True)\n",
    "g = all_net_values.groupby(['strategy', 'turn'], as_index=False)['compound_value'].agg(['mean', 'std', 'count'])\n",
    "weathers = np.unique(weather)\n",
    "for strategy in strategies:\n",
    "    strategy_results = g.loc[strategy]\n",
    "    xp = strategy_results.index\n",
    "    yp = strategy_results['mean'].values\n",
    "    yerr = strategy_results['std'].values\n",
    "    p = ax.plot(xp, yp, linewidth=1, marker='o', markersize=5, label=strategy)\n",
    "    p = ax.errorbar(xp, yp, yerr=yerr, alpha=0.4, color=p[0].get_color())\n",
    "    if (strategy == 'top'):\n",
    "        compound_value_err_top = yerr\n",
    "    if (strategy == 'smart'):\n",
    "        compound_value_err_smart = yerr\n",
    "p = ax.set_title('mean compound_value generated by various strategies')\n",
    "p = ax.set_ylabel('compound_value')\n",
    "p = ax.set_xlabel('turn')\n",
    "p = ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot each strategy's bucket_occupation_fraction during nominal weather\n",
    "the_weather = 'nominal'\n",
    "cols = ['strategy', 'weather'] + [col for col in all_net_values.columns if ('prob' in col)]\n",
    "df = all_net_values[cols]\n",
    "avg = df.groupby(['strategy', 'weather']).mean()\n",
    "std = df.groupby(['strategy', 'weather']).std()\n",
    "count = df.groupby(['strategy', 'weather'], as_index=False).count()\n",
    "fig, ax = plt.subplots(1,1, figsize=(15, 6))\n",
    "for strategy in strategies:\n",
    "    yp = avg.loc[strategy].loc[the_weather]\n",
    "    yerr = std.loc[strategy].loc[the_weather]\n",
    "    xp = np.arange(len(yp))\n",
    "    p = ax.plot(xp, yp, linewidth=3, marker='o', markersize=3, label=strategy)\n",
    "p = ax.set_title('bucket occupation for various strategies & nominal weather')\n",
    "p = ax.set_ylabel('bucket_occupation_fraction')\n",
    "p = ax.set_xlabel('bucket number')\n",
    "p = ax.set_ylim(-0.01, 0.25)\n",
    "p = ax.set_yscale('linear')\n",
    "p = ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot smart bucket_occupation_fraction for each weather\n",
    "strategy = 'smart'\n",
    "fig, ax = plt.subplots(1,1, figsize=(15, 6))\n",
    "for the_weather in ['stormy', 'nominal', 'hot']:\n",
    "    yp = avg.loc[strategy].loc[the_weather]\n",
    "    yerr = std.loc[strategy].loc[the_weather]\n",
    "    xp = np.arange(len(yp))\n",
    "    p = ax.plot(xp, yp, linewidth=3, marker='o', markersize=4, label=the_weather)\n",
    "strategy = 'top'\n",
    "yp = avg.loc[strategy].sum()\n",
    "xp = np.arange(len(yp))\n",
    "p = ax.plot(xp, yp, linewidth=2, linestyle='--', label=strategy)\n",
    "p = ax.set_title('smart bucket occupation versus weather')\n",
    "p = ax.set_ylabel('bucket_occupation_fraction')\n",
    "p = ax.set_xlabel('bucket number')\n",
    "p = ax.set_ylim(-0.01, 0.3)\n",
    "p = ax.set_yscale('linear')\n",
    "p = ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot loss vs training epoch\n",
    "yp = compound_value_err_smart/compound_value_err_top\n",
    "xp = range(len(yp))\n",
    "fig, ax = plt.subplots(1,1, figsize=(15, 6))\n",
    "p = ax.plot(xp, yp, linewidth=3, label='smart/top uncertainty ratio')\n",
    "yp_avg = yp.mean()\n",
    "p = ax.plot(xp, yp*0 + yp_avg, linewidth=2, linestyle='--', label='mean')\n",
    "p = ax.set_title('smart/top uncertainty ratio')\n",
    "p = ax.set_ylabel(r'$\\delta_{smart}/\\delta_{top}$')\n",
    "p = ax.set_xlabel('turn')\n",
    "p = ax.legend()\n",
    "print 'mean = ', yp_avg, 1.0/np.sqrt(top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
